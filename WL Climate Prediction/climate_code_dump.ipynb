{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BRiYfWUg_8ah",
        "AsQMmXAiXvAy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Possibly useful tools"
      ],
      "metadata": {
        "id": "BRiYfWUg_8ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**how many times something occurs in a column**"
      ],
      "metadata": {
        "id": "fuPuRHIDADsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in climate_data.columns:\n",
        "  if column.startswith('STATION'):\n",
        "    results = climate_data[column].value_counts(dropna=False).to_dict() #special way to count 'NaN' values\n",
        "    print(f\"Column '{column}' counts: {results}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "ypGDkVfWOuz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**combining CSV files**"
      ],
      "metadata": {
        "id": "ESgi8gXukWHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Step 1: Set the path to your CSV files\n",
        "csv_files_path = '/content/combine/*.csv'\n",
        "\n",
        "# Step 2: Use glob to list all CSV files in the directory\n",
        "csv_files = glob.glob(csv_files_path)\n",
        "\n",
        "# Step 3: Initialize an empty list to hold DataFrames and a flag for consistency check\n",
        "data_frames = []\n",
        "consistent = True\n",
        "\n",
        "# Step 4: Loop through the list of CSV files and read each one into a DataFrame\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(file)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
        "combined_df = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Step 6: (Optional) Save the combined DataFrame to a new CSV file\n",
        "combined_df.to_csv('combined_weather_dataNEW.csv', index=False)\n",
        "\n",
        "# Step 7: Print the shape of the combined DataFrame to verify\n",
        "print('Combined DataFrame shape:', combined_df.shape)\n",
        "\n",
        "\n",
        "\n",
        "# Step 4: Loop through the list of CSV files and read each one into a DataFrame\n",
        "for file in csv_files:\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "\n",
        "        # Check if all rows in the current CSV file are the same\n",
        "        inconsistent_columns = df.columns[~df.eq(df.iloc[0]).all()]\n",
        "        if not inconsistent_columns.empty:\n",
        "            consistent = False\n",
        "            print(f\"Inconsistency found in file: {file}\")\n",
        "            print(f\"Inconsistent columns: {list(inconsistent_columns)}\")\n",
        "\n",
        "        data_frames.append(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file {file}: {e}\")\n",
        "        consistent = False\n",
        "\n",
        "if consistent:\n",
        "    # Step 5: Concatenate all DataFrames into a single DataFrame\n",
        "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "    # Step 6: (Optional) Save the combined DataFrame to a new CSV file\n",
        "    combined_df.to_csv('combined_weather_data.csv', index=False)\n",
        "\n",
        "    # Step 7: Print the shape of the combined DataFrame to verify\n",
        "    print('Combined DataFrame shape:', combined_df.shape)\n",
        "else:\n",
        "    print(\"Not all CSV files are consistent. Please check the reported files.\")"
      ],
      "metadata": {
        "id": "xyrP06bDkWbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**counting number of non-null values in every column (sorted)**"
      ],
      "metadata": {
        "id": "Cam5uYpWsGy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get non-null counts for each column\n",
        "non_null_counts = climate_data.notnull().sum()\n",
        "\n",
        "# Create a summary DataFrame\n",
        "summary_df = pd.DataFrame({\n",
        "    'Column': non_null_counts.index,\n",
        "    'Non-Null Count': non_null_counts.values\n",
        "})\n",
        "\n",
        "# Sort the summary DataFrame by 'Non-Null Count' in descending order\n",
        "sorted_summary_df = summary_df.sort_values(by='Non-Null Count', ascending=False)\n",
        "\n",
        "# Set pandas display options to prevent truncation\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Display the sorted summary\n",
        "print(sorted_summary_df)"
      ],
      "metadata": {
        "id": "Ah38XzUPsHSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# delete later?"
      ],
      "metadata": {
        "id": "AsQMmXAiXvAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling NaN values with the mean of each numeric column\n",
        "for col in climate_data.columns:\n",
        "    if col not in exclude_columns and pd.api.types.is_numeric_dtype(climate_data[col]):\n",
        "        climate_data[col] = climate_data[col].fillna(climate_data[col].mean())\n",
        "\n",
        "### /other ways to handle NaN values ###\n",
        "'''\n",
        "# (NOT RECOMMENDED) Dropping rows with NaN values:\n",
        "climate_data = climate_data.dropna()\n",
        "\n",
        "# Replacing NaN values with 0:\n",
        "climate_data = climate_data.fillna(0)\n",
        "'''"
      ],
      "metadata": {
        "id": "uaGRC2RBXygJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data\n",
        "pd.set_option('display.max_columns', None)\n",
        "#climate_data = pd.read_csv(\"/content/2024_test_3738819.csv\") #test data\n",
        "climate_data_original = pd.read_csv(\"/content/combined_weather_data.csv\")\n",
        "climate_data = climate_data_original.copy()\n",
        "\n",
        "climate_data['DATE'] = pd.to_datetime(climate_data['DATE'], format='%Y-%m-%dT%H:%M:%S') # Changing the time format\n",
        "climate_data.set_index('DATE', inplace=True) # Setting the dates as the indices (directly changing the file)\n",
        "#climate_data.tail()"
      ],
      "metadata": {
        "id": "w6_v355pYoey"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}